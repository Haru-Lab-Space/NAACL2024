{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install scikit-learn\n",
    "# !pip install focal-loss-torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxility Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "# Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_video, read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Model\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer, BertModel, BertTokenizer, BertGenerationDecoder, GPT2Config, GPT2Model, GPT2LMHeadModel, EncoderDecoderModel\n",
    "\n",
    "# Training parameter\n",
    "from torch.optim import Adam\n",
    "# Training process\n",
    "from tqdm import tqdm\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import sys\n",
    "from focal_loss.focal_loss import FocalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "def write_json(path, data):\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "def mkdir(path):\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(path)\n",
    "        print(\"The new directory checkpoint is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, config_path, data, option=\"train\"):\n",
    "        super(ConversationDataset, self).__init__()\n",
    "        self.build(config_path)\n",
    "        self.data = data\n",
    "        self.option = option\n",
    "    def build(self, config_path):\n",
    "        config = read_json(config_path)\n",
    "        self.label2id = config[\"label2id\"]\n",
    "        self.id2label = config[\"id2label\"]\n",
    "        self.tokenizer_name = config[\"tokenizer_name\"]\n",
    "        self.padding = config[\"padding\"]\n",
    "        self.paragraph_max_length = config[\"paragraph_max_length\"]\n",
    "        self.text_max_length = config[\"text_max_length\"]\n",
    "        self.left_padding = config[\"left_padding\"]\n",
    "        self.right_padding = config[\"right_padding\"]\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n",
    "        self.text_pool_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        # self.text_pool_tokenizer.add_special_tokens({'pad_token': 'eos_token_id'})\n",
    "        self.text_pool_tokenizer.pad_token = self.text_pool_tokenizer.eos_token\n",
    "    def span(self, text, subtext, ss=0):\n",
    "        if len(subtext) == 0:\n",
    "            return []\n",
    "        for i in range(ss, len(text) - len(subtext)):\n",
    "            for j in range(len(subtext)):\n",
    "                if text[i+j] != subtext[j]:\n",
    "                    match = 0\n",
    "                    break\n",
    "                else:\n",
    "                    match += 1\n",
    "                    if match == len(subtext):\n",
    "                        return [i, i+len(subtext)]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        conversation_ID = self.data[index][\"conversation_ID\"]\n",
    "        paragraph = self.tokenizer(self.data[index][\"paragraph\"], padding=self.padding, max_length=self.paragraph_max_length, return_tensors=\"pt\")\n",
    "        paragraph = torch.squeeze(paragraph['input_ids'])\n",
    "        utterance_ID = self.data[index][\"utterance_ID\"]\n",
    "        text_pool = self.data[index][\"text_pool\"]\n",
    "        speaker_pool = self.data[index][\"speaker_pool\"]\n",
    "        token_text_pool = []\n",
    "        token_speaker_pool = []\n",
    "        list_utter = copy.copy(self.data[index][\"text_utter\"])\n",
    "\n",
    "        for i in range(len(text_pool)):\n",
    "            text = self.tokenizer.encode(text_pool[i], padding=self.padding, max_length=self.text_max_length)\n",
    "            speaker = self.tokenizer(speaker_pool[i], padding=self.padding, max_length=8)[\"input_ids\"]\n",
    "            token_text_pool.append(text)\n",
    "            token_speaker_pool.append(speaker)\n",
    "\n",
    "        if len(text_pool) < self.left_padding+self.right_padding+1:\n",
    "            for i in range(len(text_pool), self.left_padding+self.right_padding+1):\n",
    "                text = self.tokenizer.encode(\"\", padding=self.padding, max_length=self.text_max_length)\n",
    "                speaker = self.tokenizer(\"\", padding=self.padding, max_length=8)[\"input_ids\"]\n",
    "                token_text_pool.insert(0, text)\n",
    "                token_speaker_pool.insert(0, speaker)\n",
    "                list_utter.insert(0, 0)\n",
    "\n",
    "\n",
    "        if self.option == \"train\":\n",
    "            label = self.label2id[self.data[index][\"emotion\"][\"property\"]]\n",
    "            emotion_label = [0] * len(self.id2label)\n",
    "            emotion_label[label] = 1\n",
    "            emotion_label = torch.FloatTensor(emotion_label)\n",
    "            casual_pool = self.data[index][\"emotion\"][\"casual\"]\n",
    "            token_casual = []\n",
    "\n",
    "\n",
    "            list = []\n",
    "            pool_label = \"\"\n",
    "         \n",
    "            for i in range(len(casual_pool)):\n",
    "                casual = [casual_pool[i][\"start\"], casual_pool[i][\"end\"]]\n",
    "                token_casual.append(casual)\n",
    "                token = self.tokenizer.encode(casual_pool[i][\"casual_text\"], add_special_tokens=False)\n",
    "                list.extend(self.span(paragraph.tolist(), token))\n",
    "                if len(casual_pool[i][\"casual_text\"]) != 0:\n",
    "                    pool_label += \" \" + casual_pool[i][\"casual_text\"]\n",
    "\n",
    "            for i in range(len(casual_pool), self.left_padding+self.right_padding+1):\n",
    "                casual = [0, 0]\n",
    "                token_casual.insert(0, casual)\n",
    "            # print(casual_pool)\n",
    "            # print(list)\n",
    "            paragraph_label = [0] * self.paragraph_max_length\n",
    "            for i in list:\n",
    "                paragraph_label[i] = 1\n",
    "\n",
    "            # print(\"list_utter\"+str(list_utter))\n",
    "            # print(\"token_text_pool\"+str(token_text_pool))\n",
    "\n",
    "            return {\n",
    "                \"conversation_ID\": conversation_ID,\n",
    "                \"paragraph\": paragraph,\n",
    "                \"paragraph_label\": torch.FloatTensor(paragraph_label),\n",
    "                \"pool_label\": self.tokenizer(pool_label, padding=self.padding, max_length=self.paragraph_max_length, return_tensors=\"pt\")[\"input_ids\"],\n",
    "                \"utterance_ID\": utterance_ID,\n",
    "                \"token_text_pool\": torch.FloatTensor(token_text_pool),\n",
    "                \"text_utter_pool\": torch.FloatTensor(list_utter),\n",
    "                \"token_speaker_pool\": torch.FloatTensor(token_speaker_pool),\n",
    "                \"emotion_label\": emotion_label,\n",
    "                \"span_label\": torch.FloatTensor(token_casual)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"conversation_ID\": conversation_ID,\n",
    "                \"paragraph\": paragraph,\n",
    "                \"utterance_ID\": utterance_ID,\n",
    "                \"token_text_pool\": torch.FloatTensor(token_text_pool),\n",
    "                \"text_utter_pool\": torch.FloatTensor(list_utter),\n",
    "                \"token_speaker_pool\": torch.FloatTensor(token_speaker_pool),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    def __init__(self, config_path):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.layers_to_freeze = []\n",
    "        self.history = {\n",
    "            \"train loss\": [],\n",
    "            \"valid loss\": [],\n",
    "            \"emotion_correct\": [],\n",
    "            \"span_correct\": []\n",
    "        }\n",
    "        self.build(config_path)\n",
    "    def build(self, config_path):\n",
    "        print(config_path)\n",
    "        config = read_json(config_path)\n",
    "        self.patience = config['patience']\n",
    "        self.min_delta = config['min_delta']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.device = config['device']\n",
    "        self.save_checkpoint_dir = config['output_dir'] + \"/checkpoint\"\n",
    "        self.save_history_dir = config['output_dir'] + \"/history\"\n",
    "        self.emotion_head_layers = config['emotion_head_layers']\n",
    "        self.casual_head_layers = config['casual_head_layers']\n",
    "        self.decoder_layers = config['decoder_layers']\n",
    "        self.encoder_layers = config['encoder_layers']\n",
    "        self.lstm_layers = config['lstm_layers']\n",
    "        self.alpha_focal_loss = config['alpha_focal_loss']\n",
    "        self.gamma_focal_loss = config['gamma_focal_loss']\n",
    "        self.label2id = config['label2id']\n",
    "        self.target_names = self.label2id.keys()\n",
    "        self.early_stopper = EarlyStopper(self.patience, self.min_delta)\n",
    "\n",
    "        mkdir(self.save_history_dir)\n",
    "\n",
    "    def emotion_head_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers + self.encoder_layers + self.lstm_layers\n",
    "        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "    def emotion_encoder_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers + self.lstm_layers\n",
    "        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "    def emotion_encoder_lstm_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers + self.decoder_layers \n",
    "    def emotion_casual_head_training(self):\n",
    "        self.layers_to_freeze = self.encoder_layers + self.lstm_layers\n",
    "    def emotion_casual_lstm_head_training(self):\n",
    "        self.layers_to_freeze = self.encoder_layers\n",
    "        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "    def emotion_lstm_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers + self.encoder_layers\n",
    "        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "        \n",
    "    def casual_head_training(self):\n",
    "        self.layers_to_freeze = self.emotion_head_layers + self.encoder_layers + self.lstm_layers\n",
    "\n",
    "    def full_training(self):\n",
    "        self.layers_to_freeze = []\n",
    "    def freeze(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if any(layer in name for layer in self.layers_to_freeze):\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "        return model\n",
    "    def train(self, model, optimizer, train_dataset, valid_dataset, epochs, option=\"emotion_head\", batch_size=None):\n",
    "        self.optimizer = optimizer\n",
    "        if option == \"emotion_head\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_head_training()\n",
    "        elif option == \"emotion_encoder\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_encoder_training()\n",
    "        elif option == \"emotion_lstm\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_lstm_training()\n",
    "        elif option == \"emotion_encoder_lstm\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_encoder_lstm_training()\n",
    "        elif option == \"emotion_casual_head\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_casual_head_training()\n",
    "        elif option == \"emotion_casual_lstm_head\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_casual_lstm_head_training()\n",
    "        elif option == \"casual_head\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.casual_head_training()\n",
    "        elif option == \"full\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.full_training()\n",
    "        else:\n",
    "            print(\"Option fail\")\n",
    "            return\n",
    "\n",
    "        if batch_size == None:\n",
    "            self.batch_size = self.batch_size_config\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        mkdir(self.save_checkpoint_dir + \"/\" + option)\n",
    "        self.fn_loss = nn.CrossEntropyLoss()\n",
    "        self.span_fn_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "        print(\"device: \"+str(self.device))\n",
    "        print(\"batch_size: \"+str(self.batch_size))\n",
    "        print(\"gamma_focal_loss: \"+str(self.gamma_focal_loss))\n",
    "        print(\"alpha_focal_loss: \"+str(self.alpha_focal_loss))\n",
    "\n",
    "        self.early_stopper.reset()\n",
    "        self.model = self.freeze(model)\n",
    "        # if self.device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "        #     print(\"Training Parallel!\")\n",
    "        #     self.model = nn.DataParallel(self.model)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.train_dataloader = DataLoader(dataset=train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "        self.valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        self.epochs = epochs\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = self._train_epoch(epoch, option)\n",
    "            val_loss, emotion_correct, span_correct, emotion_label_list, emotion_pred_list = self._val_epoch(epoch, option)\n",
    "            \n",
    "            self.history[\"train loss\"].append(train_loss)\n",
    "            self.history[\"valid loss\"].append(val_loss)\n",
    "            self.history[\"emotion_correct\"].append(emotion_correct)\n",
    "            self.history[\"span_correct\"].append(span_correct)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.save_checkpoint(epoch, option)\n",
    "                print(f\"Epoch {epoch+1}: Train loss {train_loss:.4f},  Valid loss {val_loss:.4f},  emotion_correct {emotion_correct*100:.4f}%,  span_correct {span_correct*100:.4f}%\")\n",
    "                print(classification_report(emotion_label_list, emotion_pred_list, target_names=self.target_names))\n",
    "            if self.early_stopper.early_stop(val_loss):\n",
    "                print(\"Early stop at epoch: \"+str(epoch) + \" with valid loss: \"+str(val_loss))\n",
    "                break\n",
    "\n",
    "        \n",
    "        write_json(self.save_history_dir + \"/\" + option + \"_history.json\", self.history) \n",
    "        \n",
    "    def _train_epoch(self, epoch, option):\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        logger_message = f'Training epoch {epoch}/{self.epochs}'\n",
    "\n",
    "        progress_bar = tqdm(self.train_dataloader,\n",
    "                            desc=logger_message, initial=0, dynamic_ncols=True)\n",
    "        for batch, data in enumerate(progress_bar):\n",
    "            conversation_id = data[\"conversation_ID\"]\n",
    "            paragraph = data[\"paragraph\"].to(self.device)\n",
    "            span_label = data[\"paragraph_label\"].to(self.device)\n",
    "            pool_label = data[\"pool_label\"].to(self.device)\n",
    "            utter_id = data[\"utterance_ID\"]\n",
    "            token_text_pool = data[\"token_text_pool\"].to(self.device)\n",
    "            token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n",
    "            emotion_label = data[\"emotion_label\"].to(self.device)\n",
    "            # span_label = data[\"span_label\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            # print(\"train:    333 2\")\n",
    "            \n",
    "            emotion_pred, span_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n",
    "            \n",
    "            emotion_label = torch.argmax(emotion_label, dim=-1)\n",
    "            if option == \"emotion_head\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"emotion_lstm\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"emotion_encoder\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"emotion_encoder_lstm\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"emotion_casual_head\":\n",
    "                emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                loss = emotion_loss + span_loss\n",
    "            elif option == \"emotion_casual_lstm_head\":\n",
    "                emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                loss = emotion_loss + span_loss\n",
    "            elif option == \"full\":\n",
    "                emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                loss = emotion_loss + span_loss\n",
    "            elif option == \"casual_head\":\n",
    "                loss = self.fn_loss(span_pred, span_label)\n",
    "            else:\n",
    "                emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                loss = emotion_loss + span_loss\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return train_loss / len(self.train_dataloader)\n",
    "\n",
    "    def _val_epoch(self, epoch, option):\n",
    "        self.model.eval()\n",
    "        valid_loss = 0.0\n",
    "        emotion_correct=0\n",
    "        span_correct=0\n",
    "        emotion_pred_list = []\n",
    "        emotion_label_list = []\n",
    "        logger_message = f'Validation epoch {epoch}/{self.epochs}'\n",
    "        progress_bar = tqdm(self.valid_dataloader,\n",
    "                            desc=logger_message, initial=0, dynamic_ncols=True)\n",
    "        with torch.no_grad():\n",
    "            for _, data in enumerate(progress_bar):\n",
    "                conversation_id = data[\"conversation_ID\"]\n",
    "                paragraph = data[\"paragraph\"].to(self.device)\n",
    "                span_label = data[\"paragraph_label\"].to(self.device)\n",
    "                pool_label = data[\"pool_label\"].to(self.device)\n",
    "                utter_id = data[\"utterance_ID\"]\n",
    "                token_text_pool = data[\"token_text_pool\"].to(self.device)\n",
    "                token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n",
    "                emotion_label = data[\"emotion_label\"].to(self.device)\n",
    "                # span_label = data[\"span_label\"].to(self.device)\n",
    "                emotion_pred, span_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                emotion_label = torch.argmax(emotion_label, dim=-1)\n",
    "                if option == \"emotion_head\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"emotion_lstm\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"emotion_encoder\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"emotion_encoder_lstm\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"emotion_casual_head\":\n",
    "                    emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                    span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                    loss = emotion_loss + span_loss\n",
    "                elif option == \"emotion_casual_lstm_head\":\n",
    "                    emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                    span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                    loss = emotion_loss + span_loss\n",
    "                elif option == \"full\":\n",
    "                    emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                    span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                    loss = emotion_loss + span_loss\n",
    "                elif option == \"casual_head\":\n",
    "                    loss = self.fn_loss(span_pred, span_label)\n",
    "                else:\n",
    "                    emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                    span_loss = self.span_fn_loss(span_pred, span_label)\n",
    "                    loss = emotion_loss + span_loss\n",
    "\n",
    "                # emotion_label_ = torch.argmax(emotion_label, dim=-1)\n",
    "                emotion_pred_ = torch.argmax(emotion_pred, dim=-1)\n",
    "                emotion_pred_list.extend(emotion_pred_.cpu().tolist())\n",
    "                emotion_label_list.extend(emotion_label.cpu().tolist())\n",
    "                # print(\"emotion_label_: \"+ str(emotion_label_))\n",
    "                # print(\"emotion_pred_: \"+ str(emotion_pred_))\n",
    "                valid_loss += loss.item()\n",
    "                emotion_correct += (emotion_pred_ == emotion_label).sum().item()\n",
    "                span_correct += (torch.round(span_pred) == span_label).sum().item() / span_label.sum().item()\n",
    "        \n",
    "        return valid_loss / len(self.valid_dataloader), emotion_correct / len(self.valid_dataloader) / self.batch_size, span_correct / len(self.valid_dataloader) / self.batch_size / 16, emotion_label_list, emotion_pred_list\n",
    "        \n",
    "    def save_checkpoint(self, epoch, option):\n",
    "        checkpoint_path = os.path.join(self.save_checkpoint_dir, option + '/checkpoint_{}.pth'.format(epoch))\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(nn.Module):\n",
    "    def __init__(self, config_path):\n",
    "        super(Prediction, self).__init__()\n",
    "        self.build(config_path)\n",
    "    def build(self, config_path):\n",
    "        config = self.read_json(config_path)\n",
    "        self.id2label = config[\"id2label\"]\n",
    "        self.label2id = config[\"label2id\"]\n",
    "        self.submit_path = config[\"submit path\"]\n",
    "        self.device = config[\"device\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "    def span(self, text, subtext, ss=0):\n",
    "        if len(subtext) == 0:\n",
    "            return []\n",
    "        for i in range(ss, len(text) - len(subtext)):\n",
    "            for j in range(len(subtext)):\n",
    "                if text[i+j] != subtext[j]:\n",
    "                    match = 0\n",
    "                    break\n",
    "                else:\n",
    "                    match += 1\n",
    "                    if match == len(subtext):\n",
    "                        return [i, i+len(subtext)]\n",
    "    def predict(self, model, raw_dataset, dataset):\n",
    "        self.model = model.to(self.device)\n",
    "        self.model.eval()\n",
    "        pred_list = []\n",
    "        \n",
    "        self.test_dataloader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        logger_message = f'Predict '\n",
    "        progress_bar = tqdm(self.test_dataloader,\n",
    "                            desc=logger_message, initial=0, dynamic_ncols=True)\n",
    "        with torch.no_grad():\n",
    "            for _, data in enumerate(progress_bar):\n",
    "                conversation_id = data[\"conversation_ID\"]\n",
    "                paragraph = data[\"paragraph\"].to(self.device)\n",
    "                utter_id = data[\"utterance_ID\"]\n",
    "                token_text_pool = data[\"token_text_pool\"].to(self.device)\n",
    "                text_utter_pool = data[\"text_utter_pool\"]\n",
    "                token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n",
    "                emotion_pred, span_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n",
    "                \n",
    "                pred = self.convertpred2list(conversation_id, utter_id, emotion_pred, span_pred, paragraph.to('cpu').tolist(), token_text_pool.to('cpu').tolist(), text_utter_pool.tolist())\n",
    "                pred_list.extend(pred)\n",
    "        submit = self.convertdict2submit(self.convertpred2dict(raw_dataset, pred_list))\n",
    "        self.save_json(self.submit_path, submit)\n",
    "    def convertpred2list(self, conversation_id, utter_id, emotion_pred, span_pred, paragraph, token_text_pool):\n",
    "        pred_list = []\n",
    "        for i in range(len(emotion_pred)):\n",
    "            emotion = self.id2label[str(torch.argmax(emotion_pred[i]).item())]\n",
    "            emotion_string = str(utter_id[i].item()) + \"_\" + emotion\n",
    "            if emotion != \"neutral\":\n",
    "                # \n",
    "                span = torch.round(span_pred[i])\n",
    "\n",
    "                list_pos = []\n",
    "                for j in range(len(span)):\n",
    "                    if (span[j]) == 1:\n",
    "                        list_pos.append(j)\n",
    "\n",
    "                for j in range(len(token_text_pool[i])):\n",
    "                    inner_index = []\n",
    "                    ss, se = self.span(paragraph[i], token_text_pool[i][j][1:-1])\n",
    "                    for k in range(len(list_pos)):\n",
    "                        if np.logical_and(list_pos[k] >= ss, list_pos[k] <= se):\n",
    "                            inner_index.append(list_pos[k])\n",
    "                    \n",
    "                    if len(inner_index) == 0:\n",
    "                        continue\n",
    "                    elif len(inner_index) == 1:\n",
    "                        start_index = inner_index[0]\n",
    "                        end_index = se\n",
    "                    elif len(inner_index) > 1:\n",
    "                        start_index = inner_index[0]\n",
    "                        end_index = inner_index[-1]\n",
    "                    span_string = str(text_utter_pool[i]) + \"_\" + str(start_index) + \"_\" + str(end_index)\n",
    "                    pred_dict = {}\n",
    "                    pred_dict[\"conversation_ID\"] = conversation_id[i].item()\n",
    "                    pred_dict[\"emotion-cause_pairs\"] = [emotion_string, span_string]\n",
    "                    # print(\"pred_dict: \"+str(pred_dict))\n",
    "                    pred_list.append(pred_dict)\n",
    "\n",
    "        return pred_list\n",
    "    def convertpred2dict(self, raw_dataset, pred_list):\n",
    "        dataset = self.convertlist2dict(raw_dataset)\n",
    "        # dict = \n",
    "        for i in range(len(pred_list)):\n",
    "            pred = pred_list[i]\n",
    "            conversation_id = pred[\"conversation_ID\"]\n",
    "            # print(\"conversation_id: \"+str(conversation_id))\n",
    "            emotion_cause_pairs = pred[\"emotion-cause_pairs\"]\n",
    "            # print(\"emotion_cause_pairs: \"+str(emotion_cause_pairs))\n",
    "            if \"emotion-cause_pairs\" in dataset[conversation_id]:\n",
    "                dataset[conversation_id][\"emotion-cause_pairs\"].append(emotion_cause_pairs)\n",
    "            else:\n",
    "                dataset[conversation_id][\"emotion-cause_pairs\"] = []\n",
    "        # print(dataset)\n",
    "        return dataset\n",
    "    def convertlist2dict(self, raw_dataset):\n",
    "        dataset = {}\n",
    "        for i in range(len(raw_dataset)):\n",
    "            conversation = raw_dataset[i]\n",
    "            conversation_ID = conversation[\"conversation_ID\"]\n",
    "            # if conversation_ID not in dataset.key\n",
    "            dataset[conversation_ID] = {\n",
    "                \"conversation_ID\": conversation_ID,\n",
    "                \"conversation\": conversation['conversation']\n",
    "            }\n",
    "        return dataset\n",
    "    def convertdict2submit(self, raw_dataset):\n",
    "        dataset = []\n",
    "        for key in raw_dataset.keys():\n",
    "            # print(\"key: \"+str(key))\n",
    "            sample = raw_dataset[key]\n",
    "            # print(\"sample: \"+str(sample))\n",
    "            dataset.append(sample)\n",
    "        return dataset\n",
    "    def read_json(self, file_path):\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data\n",
    "    def save_json(self, file_path, data):\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGG(nn.Module):\n",
    "    def __init__(self, config_path):\n",
    "        super(TGG, self).__init__()\n",
    "        self.build(config_path)\n",
    "        self.lstm = nn.LSTM(self.text_max_length, self.hidden_size, self.num_layers, batch_first=True, dropout=0.2, bidirectional=True)\n",
    "        self.lstma_projection = nn.Linear(2*self.num_layers*self.hidden_size, self.embedding_dim)\n",
    "        self.cat_layer = nn.Linear(2*self.embedding_dim, self.embedding_dim)\n",
    "        self.emotion_fc = nn.Linear(self.embedding_dim, self.label_num)\n",
    "        self.casual_feedforward = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim , self.feedforward_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.feedforward_dim , self.paragraph_max_length)\n",
    "        )\n",
    "        # self.casual_fc = nn.Linear(self.embedding_dim, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def build(self, config_path):\n",
    "        config = self.read_json(config_path)\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.embedding_dim = config[\"embedding_dim\"]\n",
    "        self.feedforward_dim = config[\"feedforward_dim\"]\n",
    "        self.encoder_name = config[\"encoder_name\"]\n",
    "        self.decoder_name = config[\"decoder_name\"]\n",
    "        self.label2id = config[\"label2id\"]\n",
    "        self.label_num = len(self.label2id)\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.paragraph_max_length = config[\"paragraph_max_length\"]\n",
    "        self.text_max_length = config[\"text_max_length\"]\n",
    "        self.left_padding = config[\"left_padding\"]\n",
    "        self.right_padding = config[\"right_padding\"]\n",
    "        self.padding = config[\"padding\"]\n",
    "        self.num_text = 1 + self.left_padding + self.right_padding\n",
    "        self.device = config[\"device\"]\n",
    "        \n",
    "        main_part = AutoModel.from_pretrained(self.encoder_name)\n",
    "        self.encoder_embeddings = main_part.embeddings\n",
    "        self.encoder_encoder = main_part.encoder\n",
    "        self.encoder_pooler = main_part.pooler\n",
    "        # self.encoder_decoder = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
    "        \n",
    "        # self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        # self.encoder_decoder.config.decoder_start_token_id = self.tokenizer.cls_token_id\n",
    "        # self.encoder_decoder.config.pad_token_id = self.tokenizer.pad_token_id\n",
    "        # self.encoder_decoder.config.vocab_size = self.encoder_decoder.config.decoder.vocab_size\n",
    "        # self.encoder_embeddings = main_part.encoder.embeddings\n",
    "        # self.encoder_encoder = main_part.encoder.encoder\n",
    "        # self.encoder_pooler = main_part.encoder.pooler\n",
    "        # self.decoder_embeddings = main_part.decoder.bert.embeddings\n",
    "        # self.decoder_encoder = main_part.decoder.bert.encoder\n",
    "        # self.decoder_pooler = main_part.decoder.bert.pooler\n",
    "\n",
    "        # main_part_2 = GPT2LMHeadModel.from_pretrained(self.decoder_name, output_hidden_states =True)\n",
    "        \n",
    "    def forward(self, paragraph, token_text_pool, token_speaker_pool):\n",
    "        batch_size = paragraph.size(0)\n",
    "        device = paragraph.get_device()\n",
    "\n",
    "        h0 = torch.randn((2 * self.num_layers, batch_size, self.hidden_size), device=device)\n",
    "        c0 = torch.randn((2 * self.num_layers, batch_size, self.hidden_size), device=device)\n",
    "        output, (hn, cn) = self.lstm(token_text_pool, (h0, c0))\n",
    "        hn = hn.permute(1,0,2)\n",
    "        hn = self.lstma_projection(hn.reshape(batch_size, -1))\n",
    "        \n",
    "        _paragraph = self.encoder_embeddings(paragraph)\n",
    "        _paragraph = self.encoder_encoder(_paragraph)['last_hidden_state']\n",
    "        _paragraph = self.encoder_pooler(_paragraph)\n",
    "        # _paragraph_de = self.encoder_embeddings(paragraph)\n",
    "        # _paragraph_de = self.encoder_encoder(_paragraph_de)['last_hidden_state']\n",
    "        # _paragraph_de = self.encoder_pooler(_paragraph_de)\n",
    "        # print(\"_paragraph:\"+str(_paragraph.shape))\n",
    "\n",
    "        hidden_state = torch.cat([hn, _paragraph], dim=-1)\n",
    "\n",
    "        _x = self.cat_layer(hidden_state)\n",
    "        # print(\"_x:\"+str(_x.shape))\n",
    "        # labels = self.tokenizer(\"\", padding=self.padding, max_length=self.paragraph_max_length, return_tensors=\"pt\").input_ids.to(device).expand(batch_size, -1)\n",
    "        # print(\"labels:\"+str(labels.shape))\n",
    "        # print(\"paragraph:\"+str(paragraph.shape))\n",
    "        # _x = self.encoder_decoder(input_ids=paragraph, labels=labels, output_hidden_states=True)\n",
    "        # print(\"_x:\"+str(_x.shape))\n",
    "        _e_category = self.emotion_fc(_x)\n",
    "        # print(\"_e_category:\"+str(_e_category.shape))\n",
    "\n",
    "        _x = self.casual_feedforward(_x)\n",
    "        # print(\"_x:\"+str(_x.shape))\n",
    "        # _x = F.cosine_similarity(_x, paragraph, dim=-1)\n",
    "        # print(\"_x:\"+str(_x.shape))\n",
    "        _x = self.sigmoid(_x)\n",
    "        # print(\"_x:\"+str(_x.shape))\n",
    "        return self.softmax(_e_category), _x\n",
    "    def read_json(self, file_path):\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"config.json\"\n",
    "train_data = read_json(\"../data/ECF 2.0/train/augment_train.json\")\n",
    "valid_data = read_json(\"../data/ECF 2.0/train/augment_valid.json\")\n",
    "# trial_data = read_json(\"../data/ECF 2.0/trial/trial.json\")\n",
    "# raw_trial_data = read_json(\"../data/ECF 2.0/trial/Subtask_1_trial.json\")\n",
    "\n",
    "train_dataset = ConversationDataset(config_path, train_data)\n",
    "valid_dataset = ConversationDataset(config_path, valid_data)\n",
    "model = TGG(config_path)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(\"\\\"\" + name + \"\\\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING emotion_head MODEL\n",
      "device: cuda\n",
      "batch_size: 128\n",
      "gamma_focal_loss: 2\n",
      "alpha_focal_loss: [1, 5, 5, 1, 1, 3, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0/100: 100%|██████████| 101/101 [02:00<00:00,  1.19s/it]\n",
      "Validation epoch 0/100: 100%|██████████| 26/26 [00:29<00:00,  1.14s/it]\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 2.0193,  Valid loss 2.0213,  emotion_correct 13.8522%,  span_correct 3.6415%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       461\n",
      "     disgust       0.00      0.00      0.00       461\n",
      "        fear       0.00      0.00      0.00       461\n",
      "         joy       0.00      0.00      0.00       461\n",
      "     neutral       0.00      0.00      0.00       461\n",
      "     sadness       0.00      0.00      0.00       461\n",
      "    surprise       0.14      1.00      0.25       461\n",
      "\n",
      "    accuracy                           0.14      3227\n",
      "   macro avg       0.02      0.14      0.04      3227\n",
      "weighted avg       0.02      0.14      0.04      3227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/100: 100%|██████████| 101/101 [01:51<00:00,  1.10s/it]\n",
      "Validation epoch 1/100: 100%|██████████| 26/26 [00:27<00:00,  1.06s/it]\n",
      "Training epoch 2/100: 100%|██████████| 101/101 [01:52<00:00,  1.11s/it]\n",
      "Validation epoch 2/100: 100%|██████████| 26/26 [00:27<00:00,  1.04s/it]\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss 2.0228,  Valid loss 2.0213,  emotion_correct 13.8522%,  span_correct 3.6423%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       461\n",
      "     disgust       0.00      0.00      0.00       461\n",
      "        fear       0.00      0.00      0.00       461\n",
      "         joy       0.00      0.00      0.00       461\n",
      "     neutral       0.00      0.00      0.00       461\n",
      "     sadness       0.00      0.00      0.00       461\n",
      "    surprise       0.14      1.00      0.25       461\n",
      "\n",
      "    accuracy                           0.14      3227\n",
      "   macro avg       0.02      0.14      0.04      3227\n",
      "weighted avg       0.02      0.14      0.04      3227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3/100: 100%|██████████| 101/101 [01:48<00:00,  1.07s/it]\n",
      "Validation epoch 3/100: 100%|██████████| 26/26 [00:26<00:00,  1.04s/it]\n",
      "Training epoch 4/100: 100%|██████████| 101/101 [01:50<00:00,  1.09s/it]\n",
      "Validation epoch 4/100: 100%|██████████| 26/26 [00:26<00:00,  1.03s/it]\n",
      "Training epoch 5/100: 100%|██████████| 101/101 [01:49<00:00,  1.09s/it]\n",
      "Validation epoch 5/100: 100%|██████████| 26/26 [00:26<00:00,  1.02s/it]\n",
      "Training epoch 6/100: 100%|██████████| 101/101 [01:49<00:00,  1.09s/it]\n",
      "Validation epoch 6/100: 100%|██████████| 26/26 [00:26<00:00,  1.03s/it]\n",
      "Training epoch 7/100: 100%|██████████| 101/101 [01:52<00:00,  1.11s/it]\n",
      "Validation epoch 7/100: 100%|██████████| 26/26 [00:27<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at epoch: 7 with valid loss: 2.021279752254486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_head\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING emotion_lstm MODEL\n",
      "device: cuda\n",
      "batch_size: 128\n",
      "gamma_focal_loss: 2\n",
      "alpha_focal_loss: [1, 5, 5, 1, 1, 3, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0/100: 100%|██████████| 101/101 [01:52<00:00,  1.11s/it]\n",
      "Validation epoch 0/100: 100%|██████████| 26/26 [00:27<00:00,  1.04s/it]\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 2.0225,  Valid loss 2.0213,  emotion_correct 13.8522%,  span_correct 3.6937%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       461\n",
      "     disgust       0.00      0.00      0.00       461\n",
      "        fear       0.00      0.00      0.00       461\n",
      "         joy       0.00      0.00      0.00       461\n",
      "     neutral       0.00      0.00      0.00       461\n",
      "     sadness       0.00      0.00      0.00       461\n",
      "    surprise       0.14      1.00      0.25       461\n",
      "\n",
      "    accuracy                           0.14      3227\n",
      "   macro avg       0.02      0.14      0.04      3227\n",
      "weighted avg       0.02      0.14      0.04      3227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/100: 100%|██████████| 101/101 [01:47<00:00,  1.06s/it]\n",
      "Validation epoch 1/100: 100%|██████████| 26/26 [00:26<00:00,  1.02s/it]\n",
      "Training epoch 2/100: 100%|██████████| 101/101 [01:51<00:00,  1.10s/it]\n",
      "Validation epoch 2/100: 100%|██████████| 26/26 [00:26<00:00,  1.03s/it]\n",
      "Training epoch 3/100: 100%|██████████| 101/101 [01:51<00:00,  1.10s/it]\n",
      "Validation epoch 3/100: 100%|██████████| 26/26 [00:26<00:00,  1.03s/it]\n",
      "Training epoch 4/100: 100%|██████████| 101/101 [01:52<00:00,  1.11s/it]\n",
      "Validation epoch 4/100: 100%|██████████| 26/26 [00:27<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at epoch: 4 with valid loss: 2.021279752254486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_lstm\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING emotion_casual_lstm_head MODEL\n",
      "device: cuda\n",
      "batch_size: 128\n",
      "gamma_focal_loss: 2\n",
      "alpha_focal_loss: [1, 5, 5, 1, 1, 3, 1]\n",
      "Training Parallel!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0/100: 100%|██████████| 101/101 [01:32<00:00,  1.09it/s]\n",
      "Validation epoch 0/100: 100%|██████████| 26/26 [00:22<00:00,  1.17it/s]\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 11.1833,  Valid loss 11.1017,  emotion_correct 13.8522%,  span_correct 5.3666%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       461\n",
      "     disgust       0.00      0.00      0.00       461\n",
      "        fear       0.00      0.00      0.00       461\n",
      "         joy       0.00      0.00      0.00       461\n",
      "     neutral       0.00      0.00      0.00       461\n",
      "     sadness       0.14      1.00      0.25       461\n",
      "    surprise       0.00      0.00      0.00       461\n",
      "\n",
      "    accuracy                           0.14      3227\n",
      "   macro avg       0.02      0.14      0.04      3227\n",
      "weighted avg       0.02      0.14      0.04      3227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/100:   0%|          | 0/101 [00:00<?, ?it/s]/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/rnn.py:691: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Training epoch 1/100: 100%|██████████| 101/101 [01:32<00:00,  1.09it/s]\n",
      "Validation epoch 1/100: 100%|██████████| 26/26 [00:22<00:00,  1.16it/s]\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss 11.1607,  Valid loss 11.0931,  emotion_correct 13.8522%,  span_correct 5.3940%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       461\n",
      "     disgust       0.00      0.00      0.00       461\n",
      "        fear       0.00      0.00      0.00       461\n",
      "         joy       0.00      0.00      0.00       461\n",
      "     neutral       0.00      0.00      0.00       461\n",
      "     sadness       0.14      1.00      0.25       461\n",
      "    surprise       0.00      0.00      0.00       461\n",
      "\n",
      "    accuracy                           0.14      3227\n",
      "   macro avg       0.02      0.14      0.04      3227\n",
      "weighted avg       0.02      0.14      0.04      3227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2/100:   0%|          | 0/101 [00:00<?, ?it/s]/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/rnn.py:691: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Training epoch 2/100: 100%|██████████| 101/101 [01:31<00:00,  1.11it/s]\n",
      "Validation epoch 2/100: 100%|██████████| 26/26 [00:21<00:00,  1.19it/s]\n",
      "Training epoch 3/100: 100%|██████████| 101/101 [01:31<00:00,  1.10it/s]\n",
      "Validation epoch 3/100: 100%|██████████| 26/26 [00:21<00:00,  1.20it/s]\n",
      "Training epoch 4/100: 100%|██████████| 101/101 [01:31<00:00,  1.10it/s]\n",
      "Validation epoch 4/100: 100%|██████████| 26/26 [00:21<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at epoch: 4 with valid loss: 11.093136714054989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_casual_lstm_head\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING full MODEL\n",
      "device: cuda\n",
      "batch_size: 32\n",
      "gamma_focal_loss: 2\n",
      "alpha_focal_loss: [1, 5, 5, 1, 1, 3, 1]\n",
      "Training Parallel!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0/100:   0%|          | 0/403 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_4112826/2008320485.py\", line 65, in forward\n    _paragraph = self.encoder_encoder(_paragraph)['last_hidden_state']\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 607, in forward\n    layer_outputs = layer_module(\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 539, in forward\n    layer_output = apply_chunking_to_forward(\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/pytorch_utils.py\", line 242, in apply_chunking_to_forward\n    return forward_fn(*input_tensors)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 552, in feed_forward_chunk\n    layer_output = self.output(intermediate_output, attention_output)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 466, in forward\n    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/normalization.py\", line 189, in forward\n    return F.layer_norm(\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/functional.py\", line 2347, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.76 GiB total capacity; 7.08 GiB already allocated; 5.56 MiB free; 7.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 121\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, model, optimizer, train_dataset, valid_dataset, epochs, option, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 121\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     val_loss, emotion_correct, span_correct, emotion_label_list, emotion_pred_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_val_epoch(epoch, option)\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[18], line 160\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch, option)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# span_label = data[\"span_label\"].to(self.device)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 160\u001b[0m emotion_pred, span_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_text_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_speaker_pool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m emotion_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(emotion_label, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m option \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_head\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/_utils.py:434\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_4112826/2008320485.py\", line 65, in forward\n    _paragraph = self.encoder_encoder(_paragraph)['last_hidden_state']\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 607, in forward\n    layer_outputs = layer_module(\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 539, in forward\n    layer_output = apply_chunking_to_forward(\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/pytorch_utils.py\", line 242, in apply_chunking_to_forward\n    return forward_fn(*input_tensors)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 552, in feed_forward_chunk\n    layer_output = self.output(intermediate_output, attention_output)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 466, in forward\n    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/normalization.py\", line 189, in forward\n    return F.layer_norm(\n  File \"/root/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/functional.py\", line 2347, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.76 GiB total capacity; 7.08 GiB already allocated; 5.56 MiB free; 7.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"full\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_casual_head\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_head\", batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_encoder\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_encoder_lstm\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_dataset = ConversationDataset(config_path, trial_data, option=\"trial\")\n",
    "predict = Prediction(config_path)\n",
    "predict.predict(model, raw_trial_data, trial_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
