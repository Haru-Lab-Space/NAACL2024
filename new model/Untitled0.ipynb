{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29945,"status":"ok","timestamp":1705654628699,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"y2MXg2LygJlh","outputId":"2632607f-f959-4de9-a3ad-db23e451dd3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (4.36.2)\n","Requirement already satisfied: filelock in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (0.20.2)\n","Requirement already satisfied: numpy>=1.17 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (1.24.1)\n","Requirement already satisfied: packaging>=20.0 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from transformers) (4.64.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from requests->transformers) (2023.11.17)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: scikit-learn in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (1.3.2)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from scikit-learn) (1.24.1)\n","Requirement already satisfied: scipy>=1.5.0 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from scikit-learn) (3.2.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: focal-loss-torch in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (0.1.2)\n","Requirement already satisfied: torch in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from focal-loss-torch) (1.10.0+cu113)\n","Requirement already satisfied: numpy in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from focal-loss-torch) (1.24.1)\n","Requirement already satisfied: typing-extensions in /root/anaconda3/envs/diffusion/lib/python3.8/site-packages (from torch->focal-loss-torch) (4.9.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers\n","!pip install scikit-learn\n","!pip install focal-loss-torch"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3594,"status":"ok","timestamp":1705654632290,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"9d-SWauVh2st","outputId":"45810083-460c-4545-b5e4-8db21d631b1f"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3758,"status":"ok","timestamp":1705654636046,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"O4qgnIm-h396"},"outputs":[],"source":["import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","# Dataset\n","from PIL import Image\n","from torchvision import transforms\n","from torchvision.io import read_video, read_image\n","from torch.utils.data import Dataset, DataLoader\n","# Model\n","from transformers import AutoModel\n","from transformers import AutoTokenizer, BertModel, BertTokenizer, BertGenerationDecoder, GPT2Config, GPT2Model, GPT2LMHeadModel\n","\n","# Training parameter\n","from torch.optim import Adam\n","# Training process\n","from tqdm import tqdm\n","# Metrics\n","from sklearn.metrics import classification_report, accuracy_score\n","from collections import OrderedDict\n","import copy\n","import sys\n","from focal_loss.focal_loss import FocalLoss"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1705654636047,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"26CvxNTOh5xu"},"outputs":[],"source":["def read_json(file_path):\n","    with open(file_path, 'r') as json_file:\n","        data = json.load(json_file)\n","    return data\n","def write_json(path, data):\n","    with open(path, 'w') as json_file:\n","        json.dump(data, json_file, indent=4)\n","def mkdir(path):\n","    isExist = os.path.exists(path)\n","    if not isExist:\n","        # Create a new directory because it does not exist\n","        os.makedirs(path)\n","        print(\"The new directory checkpoint is created!\")\n","def count(data):\n","    dictionary = {}\n","\n","    for item in data:\n","        # print( dictionary.keys())\n","        emotion = item['emotion']['property']\n","        if emotion in dictionary.keys():\n","            # print(emotion)\n","            dictionary[emotion] +=1\n","        else:\n","            # print(emotion)\n","            dictionary[emotion] =1\n","    return dictionary"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705654636047,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"fCAwxvkzh7JI"},"outputs":[],"source":["class EarlyStopper:\n","    def __init__(self, patience=1, min_delta=0):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.min_validation_loss = float('inf')\n","\n","    def reset(self):\n","        self.counter = 0\n","\n","    def early_stop(self, validation_loss):\n","        if validation_loss < (self.min_validation_loss + self.min_delta):\n","            self.min_validation_loss = validation_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        return False"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705654636047,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"W9-ZmikNiB8B"},"outputs":[],"source":["class ConversationDataset(Dataset):\n","    def __init__(self, config_path, data, option=\"train\"):\n","        super(ConversationDataset, self).__init__()\n","        self.build(config_path)\n","        self.data = data\n","        self.option = option\n","    def build(self, config_path):\n","        config = read_json(config_path)\n","        self.label2id = config[\"label2id\"]\n","        self.id2label = config[\"id2label\"]\n","        self.tokenizer_name = config[\"tokenizer_name\"]\n","        self.padding = config[\"padding\"]\n","        self.paragraph_max_length = config[\"paragraph_max_length\"]\n","        self.text_max_length = config[\"text_max_length\"]\n","        self.left_padding = config[\"left_padding\"]\n","        self.right_padding = config[\"right_padding\"]\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n","        self.text_pool_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","        # self.text_pool_tokenizer.add_special_tokens({'pad_token': 'eos_token_id'})\n","        self.text_pool_tokenizer.pad_token = self.text_pool_tokenizer.eos_token\n","    def __len__(self):\n","        return len(self.data)\n","    def __getitem__(self, index):\n","        conversation_ID = self.data[index][\"conversation_ID\"]\n","        paragraph = self.tokenizer(self.data[index][\"paragraph\"], padding=self.padding, max_length=self.paragraph_max_length, return_tensors=\"pt\")\n","        paragraph = torch.squeeze(paragraph['input_ids'])\n","        utterance_ID = self.data[index][\"utterance_ID\"]\n","        text_pool = self.data[index][\"text_pool\"]\n","        speaker_pool = self.data[index][\"speaker_pool\"]\n","        token_text_pool = []\n","        token_speaker_pool = []\n","\n","        for i in range(len(text_pool)):\n","            text = self.tokenizer.encode(text_pool[i], padding=self.padding, max_length=self.text_max_length)\n","            speaker = self.tokenizer(speaker_pool[i], padding=self.padding, max_length=8)[\"input_ids\"]\n","            token_text_pool.append(text)\n","            token_speaker_pool.append(speaker)\n","\n","        if len(text_pool) < self.left_padding+self.right_padding+1:\n","            for i in range(len(text_pool), self.left_padding+self.right_padding+1):\n","                text = self.tokenizer.encode(\"\", padding=self.padding, max_length=self.text_max_length)\n","                speaker = self.tokenizer(\"\", padding=self.padding, max_length=8)[\"input_ids\"]\n","                token_text_pool.insert(0, text)\n","                token_speaker_pool.insert(0, speaker)\n","        if self.option == \"train\":\n","            label = self.label2id[self.data[index][\"emotion\"][\"property\"]]\n","            emotion_label = [0] * len(self.id2label)\n","            emotion_label[label] = 1\n","            emotion_label = torch.FloatTensor(emotion_label)\n","            casual_pool = self.data[index][\"emotion\"][\"casual\"]\n","            token_casual = []\n","\n","            for i in range(len(casual_pool)):\n","                casual = [casual_pool[i][\"start\"], casual_pool[i][\"end\"]]\n","                token_casual.append(casual)\n","            # print(\" token_casual: \"+str(len(token_casual)))\n","\n","            for i in range(len(casual_pool), self.left_padding+self.right_padding+1):\n","                casual = [0, 0]\n","                token_casual.insert(0, casual)\n","            return {\n","                \"conversation_ID\": conversation_ID,\n","                \"paragraph\": paragraph,\n","                \"utterance_ID\": utterance_ID,\n","                \"token_text_pool\": torch.FloatTensor(token_text_pool),\n","                \"token_speaker_pool\": torch.FloatTensor(token_speaker_pool),\n","                \"emotion_label\": emotion_label,\n","                \"span_label\": torch.FloatTensor(token_casual)\n","            }\n","        else:\n","            return {\n","                \"conversation_ID\": conversation_ID,\n","                \"paragraph\": paragraph,\n","                \"utterance_ID\": utterance_ID,\n","                \"token_text_pool\": torch.FloatTensor(token_text_pool),\n","                \"token_speaker_pool\": torch.FloatTensor(token_speaker_pool),\n","            }"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705654636047,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"OQesjV-4iFkf"},"outputs":[],"source":["class Trainer(nn.Module):\n","    def __init__(self, config_path):\n","        super(Trainer, self).__init__()\n","        self.layers_to_freeze = []\n","        self.history = {\n","            \"train loss\": [],\n","            \"valid loss\": [],\n","            \"emotion_correct\": [],\n","            \"span_correct\": []\n","        }\n","        self.build(config_path)\n","    def build(self, config_path):\n","        print(config_path)\n","        config = read_json(config_path)\n","        self.patience = config['patience']\n","        self.min_delta = config['min_delta']\n","        self.batch_size = config['batch_size']\n","        self.device = config['device']\n","        self.save_checkpoint_dir = config['output_dir'] + \"/checkpoint\"\n","        self.save_history_dir = config['output_dir'] + \"/history\"\n","        self.emotion_head_layers = config['emotion_head_layers']\n","        self.casual_head_layers = config['casual_head_layers']\n","        self.decoder_layers = config['decoder_layers']\n","        self.encoder_layers = config['encoder_layers']\n","        self.lstm_layers = config['lstm_layers']\n","        self.alpha_focal_loss = config['alpha_focal_loss']\n","        self.gamma_focal_loss = config['gamma_focal_loss']\n","        self.label2id = config['label2id']\n","        self.target_names = self.label2id.keys()\n","        self.early_stopper = EarlyStopper(self.patience, self.min_delta)\n","\n","        mkdir(self.save_history_dir)\n","\n","    def emotion_head_training(self):\n","        self.layers_to_freeze = self.casual_head_layers + self.encoder_layers + self.decoder_layers + self.lstm_layers\n","        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n","    def emotion_encoder_training(self):\n","        self.layers_to_freeze = self.casual_head_layers + self.lstm_layers + self.decoder_layers\n","        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n","    def emotion_encoder_lstm_training(self):\n","        self.layers_to_freeze = self.casual_head_layers + self.decoder_layers\n","        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n","    def emotion_lstm_training(self):\n","        self.layers_to_freeze = self.casual_head_layers + self.encoder_layers + self.decoder_layers\n","        # self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n","\n","    def casual_head_training(self):\n","        self.layers_to_freeze = self.emotion_head_layers + self.encoder_layers + self.lstm_layers + self.decoder_layers\n","\n","    def full_training(self):\n","        self.layers_to_freeze = []\n","    def freeze(self, model):\n","        for name, param in model.named_parameters():\n","            if any(layer in name for layer in self.layers_to_freeze):\n","                param.requires_grad = False\n","            else:\n","                param.requires_grad = True\n","        return model\n","    def train(self, model, optimizer, train_dataset, valid_dataset, epochs, option=\"emotion_head\", batch_size=None):\n","        self.optimizer = optimizer\n","        best_weight = model.state_dict()\n","        if option == \"emotion_head\":\n","            print(\"TRAINING \" + option + \" MODEL\")\n","            self.emotion_head_training()\n","        elif option == \"emotion_encoder\":\n","            print(\"TRAINING \" + option + \" MODEL\")\n","            self.emotion_encoder_training()\n","        elif option == \"emotion_lstm\":\n","            print(\"TRAINING \" + option + \" MODEL\")\n","            self.emotion_lstm_training()\n","        elif option == \"emotion_encoder_lstm\":\n","            print(\"TRAINING \" + option + \" MODEL\")\n","            self.emotion_encoder_lstm_training()\n","        self.fn_loss = nn.CrossEntropyLoss()\n","        # self.loss_fn = FocalLoss(gamma=2, weights=torch.tensor([1,5,5,1,1,1,1]).to(self.device))\n","\n","        if batch_size == None:\n","            self.batch_size = self.batch_size_config\n","        else:\n","            self.batch_size = batch_size\n","        mkdir(self.save_checkpoint_dir + \"/\" + option)\n","\n","        self.early_stopper.reset()\n","        self.model = self.freeze(model)\n","        self.model = nn.DataParallel(self.model)\n","        self.model = self.model.to(self.device)\n","\n","        self.train_dataloader = DataLoader(dataset=train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=False)\n","        self.valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=self.batch_size, shuffle=False, drop_last=False)\n","\n","        best_val_loss = np.inf\n","        self.epochs = epochs\n","        for epoch in range(epochs):\n","            train_loss = self._train_epoch(epoch, option)\n","            val_loss, emotion_correct, emotion_label_list, emotion_pred_list = self._val_epoch(epoch, option)\n","\n","            self.history[\"train loss\"].append(train_loss)\n","            self.history[\"valid loss\"].append(val_loss)\n","            self.history[\"emotion_correct\"].append(emotion_correct)\n","\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                best_weight = model.state_dict()\n","                self.save_checkpoint(epoch, option)\n","                print(f\"Epoch {epoch+1}: Train loss {train_loss:.4f},  Valid loss {val_loss:.4f},  emotion_correct {emotion_correct*100:.4f}%\")\n","                print(classification_report(emotion_label_list, emotion_pred_list, target_names=self.target_names))\n","            if self.early_stopper.early_stop(val_loss):\n","                print(\"Early stop at epoch: \"+str(epoch) + \" with valid loss: \"+str(val_loss))\n","                break\n","\n","        model.load_state_dict(best_weight)\n","        write_json(self.save_history_dir + \"/\" + option + \"_history.json\", self.history)\n","\n","    def _train_epoch(self, epoch, option):\n","        self.model.train()\n","        train_loss = 0.0\n","        logger_message = f'Training epoch {epoch}/{self.epochs}'\n","\n","        progress_bar = tqdm(self.train_dataloader,\n","                            desc=logger_message, initial=0, dynamic_ncols=True)\n","        for batch, data in enumerate(progress_bar):\n","            conversation_id = data[\"conversation_ID\"]\n","            paragraph = data[\"paragraph\"].to(self.device)\n","            utter_id = data[\"utterance_ID\"]\n","            token_text_pool = data[\"token_text_pool\"].to(self.device)\n","            token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n","            emotion_label = data[\"emotion_label\"].to(self.device)\n","            self.optimizer.zero_grad()\n","            emotion_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n","            # print(\"label: \"+str(emotion_label.shape))\n","            # print(\"label: \"+str(emotion_label))\n","            # emotion_label = torch.argmax(emotion_label, dim=-1)\n","            # emotion_pred = torch.argmax(emotion_pred, dim=-1).unsqueeze(-1)\n","            # print(\"emotion_pred: \"+str(emotion_pred.shape))\n","            # print(\"emotion_pred: \"+str(emotion_pred))\n","            loss = self.loss_fn(emotion_pred, emotion_label)\n","            train_loss += loss.item()\n","            loss.backward()\n","            self.optimizer.step()\n","        return train_loss / len(self.train_dataloader)\n","\n","    def _val_epoch(self, epoch, option):\n","        self.model.eval()\n","        valid_loss = 0.0\n","        emotion_correct=0\n","        span_correct=0\n","        emotion_pred_list = []\n","        emotion_label_list = []\n","        logger_message = f'Validation epoch {epoch}/{self.epochs}'\n","        progress_bar = tqdm(self.valid_dataloader,\n","                            desc=logger_message, initial=0, dynamic_ncols=True)\n","        with torch.no_grad():\n","            for _, data in enumerate(progress_bar):\n","                conversation_id = data[\"conversation_ID\"]\n","                paragraph = data[\"paragraph\"].to(self.device)\n","                utter_id = data[\"utterance_ID\"]\n","                token_text_pool = data[\"token_text_pool\"].to(self.device)\n","                token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n","                emotion_label = data[\"emotion_label\"].to(self.device)\n","                emotion_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n","                # emotion_label = torch.argmax(emotion_label, dim=-1).unsqueeze(-1)\n","                loss = self.loss_fn(emotion_pred, emotion_label)\n","\n","                emotion_label = torch.argmax(emotion_label, dim=-1).unsqueeze(-1)\n","                emotion_pred = torch.argmax(emotion_pred, dim=-1)\n","                emotion_pred_list.extend(emotion_pred.cpu().tolist())\n","                emotion_label_list.extend(emotion_label.cpu().tolist())\n","                emotion_correct += (emotion_pred==emotion_label).sum().item()\n","                valid_loss += loss.item()\n","        return valid_loss / len(self.valid_dataloader), emotion_correct / len(self.valid_dataloader) / self.batch_size, emotion_label_list, emotion_pred_list\n","\n","    def save_checkpoint(self, epoch, option):\n","        checkpoint_path = os.path.join(self.save_checkpoint_dir, option + '/checkpoint_{}.pth'.format(epoch))\n","        torch.save({\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': self.optimizer.state_dict(),\n","            'epoch': epoch\n","        }, checkpoint_path)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705654636047,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"c7Q8Pqdji3yO"},"outputs":[],"source":["class TGG(nn.Module):\n","    def __init__(self, config_path):\n","        super(TGG, self).__init__()\n","        self.build(config_path)\n","        # self.lstm = nn.LSTM(self.text_max_length, self.hidden_size, self.num_layers, batch_first=True, dropout=0.2, bidirectional=True)\n","        # self.lstma_projection = nn.Linear(2*self.num_layers*self.hidden_size, self.embedding_dim)\n","        # self.cat_layer = nn.Linear(2*self.embedding_dim, self.embedding_dim)\n","        self.emotion_fc = nn.Linear(self.embedding_dim, self.label_num)\n","        # self.emotion_feedforward = nn.Sequential(\n","        #     nn.Linear(self.embedding_dim, 2*self.embedding_dim),\n","        #     nn.ReLU(),\n","        #     nn.Linear(2*self.embedding_dim, self.embedding_dim),\n","        #     nn.ReLU(),\n","        #     nn.Dropout(0.2)\n","        # )\n","        self.softmax = nn.Softmax(dim=-1)\n","    def build(self, config_path):\n","        config = self.read_json(config_path)\n","        self.hidden_size = config[\"hidden_size\"]\n","        self.embedding_dim = config[\"embedding_dim\"]\n","        self.encoder_name = config[\"encoder_name\"]\n","        self.decoder_name = config[\"decoder_name\"]\n","        self.label2id = config[\"label2id\"]\n","        self.label_num = len(self.label2id)\n","        self.num_layers = config[\"num_layers\"]\n","        self.paragraph_max_length = config[\"paragraph_max_length\"]\n","        self.text_max_length = config[\"text_max_length\"]\n","        self.device = config[\"device\"]\n","\n","        # main_part = AutoModel.from_pretrained(self.encoder_name)\n","        # self.embeddings = main_part.embeddings\n","        # self.encoder = main_part.encoder\n","        # self.pooler = main_part.pooler\n","        main_part = AutoModel.from_pretrained(self.encoder_name)\n","        self.embeddings = main_part.embed_tokens\n","        self.encoder = main_part.layers\n","        self.pooler = main_part.norm\n","\n","\n","    def forward(self, paragraph, token_text_pool, token_speaker_pool):\n","        batch_size = paragraph.size(0)\n","        # candidate_size = token_text_pool.size(1)\n","        # t = token_text_pool.size(2)\n","        device = paragraph.get_device()\n","\n","        # h0 = torch.randn((2 * self.num_layers, batch_size, self.hidden_size), device=device)\n","        # c0 = torch.randn((2 * self.num_layers, batch_size, self.hidden_size), device=device)\n","        # output, (hn, cn) = self.lstm(token_text_pool, (h0, c0))\n","        # hn = hn.permute(1,0,2)\n","        # hn = self.lstma_projection(hn.reshape(batch_size, -1))\n","\n","        _paragraph = self.embeddings(paragraph)\n","        _paragraph = self.encoder(_paragraph)['last_hidden_state']\n","        _paragraph = self.pooler(_paragraph)\n","\n","        # hidden_state = torch.cat([hn, _paragraph], dim=-1)\n","        # _x = self.cat_layer(hidden_state)\n","        # _x = self.emotion_feedforward(_paragraph)\n","        _e_category = self.emotion_fc(_x)\n","\n","        return self.softmax(_e_category)\n","    def read_json(self, file_path):\n","        with open(file_path, 'r') as json_file:\n","            data = json.load(json_file)\n","        return data"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":543,"status":"ok","timestamp":1705654636587,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"4O-zP_h7i_NE","outputId":"c81893f2-ff86-4f10-a6c0-f0b587b5c7df"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neutral': 1845, 'surprise': 1845, 'anger': 1845, 'sadness': 1845, 'joy': 1845, 'disgust': 1845, 'fear': 1845}\n","{'neutral': 1188, 'anger': 346, 'surprise': 329, 'fear': 61, 'sadness': 263, 'joy': 456, 'disgust': 81}\n"]}],"source":["config_path = \"/root/NAACL2024/new model/config.json\"\n","train_data = read_json(\"/root/NAACL2024/data/ECF 2.0/train/augment_train.json\")\n","valid_data = read_json(\"/root/NAACL2024/data/ECF 2.0/train/augment_valid.json\")\n","# train_data = read_json(\"/root/NAACL2024/data/ECF 2.0/train/train.json\")\n","# valid_data = read_json(\"/root/NAACL2024/data/ECF 2.0/train/valid.json\")\n","# trial_data = read_json(\"../data/ECF 2.0/trial/trial.json\")\n","# raw_trial_data = read_json(\"../data/ECF 2.0/trial/Subtask_1_trial.json\")\n","\n","print(count(train_data))\n","print(count(valid_data))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13152,"status":"ok","timestamp":1705654649738,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"whjVDZn8ue4O","outputId":"cfa0a723-7a2d-4121-c5f3-6d26083a0f47"},"outputs":[{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.0050122737884521484,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Loading checkpoint shards","rate":null,"total":2,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"17f52cfd6b6d41728177442ed6c0e781","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = ConversationDataset(config_path, train_data)\n","valid_dataset = ConversationDataset(config_path, valid_data)\n","model = TGG(config_path)\n","optimizer = Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705654649738,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"HoPfGkKLjBYp","outputId":"666cc807-bbe9-4409-a188-e15d030a7812"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root/NAACL2024/new model/config.json\n"]}],"source":["trainer = Trainer(config_path)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# for name, param in model.named_parameters():\n","#     print(\"\\\"\" + name + \"\\\",\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"elapsed":469153,"status":"error","timestamp":1705655118889,"user":{"displayName":"Duc Le Ngoc","userId":"10890292381411576176"},"user_tz":-420},"id":"yUIoYFFsjEux","outputId":"97794ca6-46fe-4d89-e965-3346020ca08e"},"outputs":[{"name":"stdout","output_type":"stream","text":["TRAINING emotion_head MODEL\n"]},{"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 10.76 GiB total capacity; 9.25 GiB already allocated; 60.56 MiB free; 9.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_head\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 86\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, model, optimizer, train_dataset, valid_dataset, epochs, option, batch_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreeze(model)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDataParallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mvalid_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py:899\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    896\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: Module._apply at line 570 (2 times)]\u001b[0m\n","File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 593\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py:897\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    896\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 10.76 GiB total capacity; 9.25 GiB already allocated; 60.56 MiB free; 9.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_head\", batch_size=2)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN2FEHAyienEkHa+3B8j8Kt","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
