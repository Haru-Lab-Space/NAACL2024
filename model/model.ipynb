{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxility Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "# Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_video, read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Model\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer, BertModel, BertTokenizer, BertGenerationDecoder\n",
    "\n",
    "# Training parameter\n",
    "from torch.optim import Adam\n",
    "# Training process\n",
    "from tqdm import tqdm\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import sys\n",
    "from focal_loss.focal_loss import FocalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "def write_json(path, data):\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "def mkdir(path):\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(path)\n",
    "        print(\"The new directory checkpoint is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, config_path, data, option=\"train\"):\n",
    "        super(ConversationDataset, self).__init__()\n",
    "        self.build(config_path)\n",
    "        self.data = data\n",
    "        self.option = option\n",
    "    def build(self, config_path):\n",
    "        config = read_json(config_path)\n",
    "        self.label2id = config[\"label2id\"]\n",
    "        self.id2label = config[\"id2label\"]\n",
    "        self.tokenizer_name = config[\"tokenizer_name\"]\n",
    "        self.padding = config[\"padding\"]\n",
    "        self.max_length = config[\"max_length\"]\n",
    "        self.left_padding = config[\"left_padding\"]\n",
    "        self.right_padding = config[\"right_padding\"]\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        conversation_ID = self.data[index][\"conversation_ID\"]\n",
    "        paragraph = self.tokenizer(self.data[index][\"paragraph\"], padding=self.padding, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        paragraph = torch.squeeze(paragraph['input_ids'])\n",
    "        utterance_ID = self.data[index][\"utterance_ID\"]\n",
    "        text_pool = self.data[index][\"text_pool\"]\n",
    "        speaker_pool = self.data[index][\"speaker_pool\"]\n",
    "        # print(\" conversation_ID: \"+str(conversation_ID))\n",
    "        # print(\" utterance_ID: \"+str(utterance_ID))\n",
    "        # print(\" text_pool: \"+str(len(text_pool)))\n",
    "        # print(\" speaker_pool: \"+str(len(speaker_pool)))\n",
    "        token_text_pool = []\n",
    "        token_speaker_pool = []\n",
    "\n",
    "        for i in range(len(text_pool)):\n",
    "            text = self.tokenizer(text_pool[i], padding=self.padding, max_length=128)[\"input_ids\"]\n",
    "            speaker = self.tokenizer(speaker_pool[i], padding=self.padding, max_length=8)[\"input_ids\"]\n",
    "            token_text_pool.append(text)\n",
    "            token_speaker_pool.append(speaker)\n",
    "\n",
    "        if len(text_pool) < self.left_padding+self.right_padding+1:\n",
    "            for i in range(len(text_pool), self.left_padding+self.right_padding+1):\n",
    "                text = self.tokenizer(\"\", padding=self.padding, max_length=128)[\"input_ids\"]\n",
    "                speaker = self.tokenizer(\"\", padding=self.padding, max_length=8)[\"input_ids\"]\n",
    "                token_text_pool.insert(0, text)\n",
    "                token_speaker_pool.insert(0, speaker)\n",
    "        # print(\" token_text_pool: \"+str(len(token_text_pool)))\n",
    "        # print(\" token_speaker_pool: \"+str(len(token_speaker_pool)))\n",
    "        if self.option == \"train\":\n",
    "            label = self.label2id[self.data[index][\"emotion\"][\"property\"]]\n",
    "            emotion_label = [0] * len(self.id2label)\n",
    "            emotion_label[label] = 1\n",
    "            emotion_label = torch.FloatTensor(emotion_label)\n",
    "            casual_pool = self.data[index][\"emotion\"][\"casual\"]\n",
    "            token_casual = []\n",
    "\n",
    "            for i in casual_pool.keys():\n",
    "                casual = [casual_pool[i][\"start\"], casual_pool[i][\"end\"]]\n",
    "                token_casual.append(casual)\n",
    "            # print(\" token_casual: \"+str(len(token_casual)))\n",
    "\n",
    "            for i in range(len(casual_pool), self.left_padding+self.right_padding+1):\n",
    "                casual = [0, 0]\n",
    "                token_casual.insert(0, casual)\n",
    "            # print(\" token_casual: \"+str(len(token_casual)))\n",
    "\n",
    "            # print(\"conversation_ID : \"+ str(conversation_ID))\n",
    "            # print(\"paragraph : \"+ str(paragraph))\n",
    "            # print(\"utterance_ID : \"+ str(utterance_ID))\n",
    "            # print(\"token_text_pool : \"+ str(token_text_pool))\n",
    "            # print(\"token_speaker_pool : \"+ str(token_speaker_pool))\n",
    "            # print(\"emotion_label : \"+ str(emotion_label))\n",
    "            # print(\"token_casual : \"+ str(token_casual))\n",
    "            return {\n",
    "                \"conversation_ID\": conversation_ID,\n",
    "                \"paragraph\": paragraph,\n",
    "                \"utterance_ID\": utterance_ID,\n",
    "                \"token_text_pool\": torch.FloatTensor(token_text_pool),\n",
    "                \"token_speaker_pool\": torch.FloatTensor(token_speaker_pool),\n",
    "                \"emotion_label\": emotion_label,\n",
    "                \"span_label\": torch.FloatTensor(token_casual)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"conversation_ID\": conversation_ID,\n",
    "                \"paragraph\": paragraph,\n",
    "                \"utterance_ID\": utterance_ID,\n",
    "                \"token_text_pool\": torch.FloatTensor(token_text_pool),\n",
    "                \"token_speaker_pool\": torch.FloatTensor(token_speaker_pool),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    def __init__(self, config_path):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.layers_to_freeze = []\n",
    "        self.history = {\n",
    "            \"train loss\": [],\n",
    "            \"valid loss\": [],\n",
    "            \"emotion_correct\": [],\n",
    "            \"span_correct\": []\n",
    "        }\n",
    "        self.build(config_path)\n",
    "    def build(self, config_path):\n",
    "        print(config_path)\n",
    "        config = read_json(config_path)\n",
    "        self.patience = config['patience']\n",
    "        self.min_delta = config['min_delta']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.device = config['device']\n",
    "        self.save_checkpoint_dir = config['output_dir'] + \"/checkpoint\"\n",
    "        self.save_history_dir = config['output_dir'] + \"/history\"\n",
    "        self.emotion_head_layers = config['emotion_head_layers']\n",
    "        self.casual_head_layers = config['casual_head_layers']\n",
    "        self.encoder_layers = config['encoder_layers']\n",
    "        self.lstm_layers = config['lstm_layers']\n",
    "        self.alpha_focal_loss = config['alpha_focal_loss']\n",
    "        self.gamma_focal_loss = config['gamma_focal_loss']\n",
    "        self.label2id = config['label2id']\n",
    "        self.target_names = self.label2id.keys()\n",
    "        self.early_stopper = EarlyStopper(self.patience, self.min_delta)\n",
    "\n",
    "        mkdir(self.save_checkpoint_dir + \"/\" + option)\n",
    "        mkdir(self.save_history_dir)\n",
    "\n",
    "    def emotion_head_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers + self.encoder_layers + self.lstm_layers\n",
    "        self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "    def emotion_encoder_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers + self.lstm_layers\n",
    "        self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "    def emotion_encoder_lstm_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers\n",
    "        self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "    def emotion_lstm_training(self):\n",
    "        self.layers_to_freeze = self.casual_head_layers + self.encoder_layers\n",
    "        self.fn_loss = FocalLoss(gamma=self.gamma_focal_loss, weights=torch.tensor(self.alpha_focal_loss).to(self.device))\n",
    "        \n",
    "    def casual_head_training(self):\n",
    "        self.layers_to_freeze = self.emotion_head_layers + self.encoder_layers + self.lstm_layers\n",
    "        self.fn_loss = nn.MSELoss()\n",
    "\n",
    "    def full_training(self):\n",
    "        self.layers_to_freeze = []\n",
    "    def freeze(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if any(layer in name for layer in self.layers_to_freeze):\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "        return model\n",
    "    def train(self, model, optimizer, train_dataset, valid_dataset, epochs, option=\"emotion_head\", batch_size=None):\n",
    "        self.optimizer = optimizer\n",
    "        if option == \"emotion_head\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_head_training()\n",
    "        elif option == \"emotion_encoder\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_encoder_training()\n",
    "        elif option == \"emotion_lstm\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_lstm_training()\n",
    "        elif option == \"emotion_encoder_lstm\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.emotion_encoder_lstm_training()\n",
    "        elif option == \"casual_head\":\n",
    "            print(\"TRAINING \" + option + \" MODEL\")\n",
    "            self.casual_head_training()\n",
    "\n",
    "        if batch_size == None:\n",
    "            self.batch_size = self.batch_size_config\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        print(\"device: \"+str(self.device))\n",
    "        print(\"batch_size: \"+str(self.batch_size))\n",
    "        print(\"gamma_focal_loss: \"+str(self.gamma_focal_loss))\n",
    "        print(\"alpha_focal_loss: \"+str(self.alpha_focal_loss))\n",
    "\n",
    "        self.early_stopper.reset()\n",
    "        self.model = self.freeze(model)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.train_dataloader = DataLoader(dataset=train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "        self.valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        self.epochs = epochs\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = self._train_epoch(epoch, option)\n",
    "            val_loss, emotion_correct, span_correct, emotion_label_list, emotion_pred_list = self._val_epoch(epoch, option)\n",
    "            \n",
    "            self.history[\"train loss\"].append(train_loss)\n",
    "            self.history[\"valid loss\"].append(val_loss)\n",
    "            self.history[\"emotion_correct\"].append(emotion_correct)\n",
    "            self.history[\"span_correct\"].append(span_correct)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.save_checkpoint(epoch, option)\n",
    "                print(f\"Epoch {epoch+1}: Train loss {train_loss:.4f},  Valid loss {val_loss:.4f},  emotion_correct {emotion_correct*100:.4f}%,  span_correct {span_correct*100:.4f}%\")\n",
    "                print(classification_report(emotion_label_list, emotion_pred_list, target_names=self.target_names))\n",
    "            if self.early_stopper.early_stop(val_loss):\n",
    "                print(\"Early stop at epoch: \"+str(epoch) + \" with valid loss: \"+str(val_loss))\n",
    "                break\n",
    "        write_json(self.save_history_dir + \"/\" + option + \"_history.json\", self.history) \n",
    "        \n",
    "    def _train_epoch(self, epoch, option):\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        logger_message = f'Training epoch {epoch}/{self.epochs}'\n",
    "\n",
    "        progress_bar = tqdm(self.train_dataloader,\n",
    "                            desc=logger_message, initial=0, dynamic_ncols=True)\n",
    "        for batch, data in enumerate(progress_bar):\n",
    "            conversation_id = data[\"conversation_ID\"]\n",
    "            paragraph = data[\"paragraph\"].to(self.device)\n",
    "            utter_id = data[\"utterance_ID\"]\n",
    "            token_text_pool = data[\"token_text_pool\"].to(self.device)\n",
    "            token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n",
    "            emotion_label = data[\"emotion_label\"].to(self.device)\n",
    "            span_label = data[\"span_label\"].to(self.device)\n",
    "            # print(\"conversation_id:\"+str(conversation_id.shape))\n",
    "            # print(\"paragraph:\"+str(paragraph.shape))\n",
    "            # print(\"casual_pool:\"+str(casual_pool.shape))\n",
    "            # print(\"emotion_label:\"+str(emotion_label.shape))\n",
    "            # print(\"span_label:\"+str(span_label.shape))\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            emotion_pred, span_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n",
    "            # print(\"emotion_label : \"+str(emotion_label.shape))\n",
    "            # print(\"span_label : \"+str(span_label.shape))\n",
    "            # print(\"emotion_pred : \"+str(emotion_pred.shape))\n",
    "            # print(\"span_pred : \"+str(span_pred.shape))\n",
    "            \n",
    "            emotion_label = torch.argmax(emotion_label, dim=-1)\n",
    "            if option == \"emotion_head\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"emotion_lstm\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"emotion_encoder\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"emotion_encoder_lstm\":\n",
    "                loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "            elif option == \"casual_head\":\n",
    "                loss = self.fn_loss(span_pred, span_label)\n",
    "            else:\n",
    "                emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                span_loss = self.fn_loss(span_pred, span_label)\n",
    "                loss = emotion_loss + span_loss\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return train_loss / len(self.train_dataloader)\n",
    "\n",
    "    def _val_epoch(self, epoch, option):\n",
    "        self.model.eval()\n",
    "        valid_loss = 0.0\n",
    "        emotion_correct=0\n",
    "        span_correct=0\n",
    "        emotion_pred_list = []\n",
    "        emotion_label_list = []\n",
    "        logger_message = f'Validation epoch {epoch}/{self.epochs}'\n",
    "        progress_bar = tqdm(self.valid_dataloader,\n",
    "                            desc=logger_message, initial=0, dynamic_ncols=True)\n",
    "        with torch.no_grad():\n",
    "            for _, data in enumerate(progress_bar):\n",
    "                conversation_id = data[\"conversation_ID\"]\n",
    "                paragraph = data[\"paragraph\"].to(self.device)\n",
    "                utter_id = data[\"utterance_ID\"]\n",
    "                token_text_pool = data[\"token_text_pool\"].to(self.device)\n",
    "                token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n",
    "                emotion_label = data[\"emotion_label\"].to(self.device)\n",
    "                span_label = data[\"span_label\"].to(self.device)\n",
    "                emotion_pred, span_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                emotion_label = torch.argmax(emotion_label, dim=-1)\n",
    "                if option == \"emotion_head\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"emotion_lstm\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"emotion_encoder\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"emotion_encoder_lstm\":\n",
    "                    loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                elif option == \"casual_head\":\n",
    "                    loss = self.fn_loss(span_pred, span_label)\n",
    "                else:\n",
    "                    emotion_loss = self.fn_loss(emotion_pred, emotion_label)\n",
    "                    span_loss = self.fn_loss(span_pred, span_label)\n",
    "                    loss = emotion_loss + span_loss\n",
    "\n",
    "                # emotion_label_ = torch.argmax(emotion_label, dim=-1)\n",
    "                emotion_pred_ = torch.argmax(emotion_pred, dim=-1)\n",
    "                emotion_pred_list.extend(emotion_pred_.cpu().tolist())\n",
    "                emotion_label_list.extend(emotion_label.cpu().tolist())\n",
    "                # print(\"emotion_label_: \"+ str(emotion_label_))\n",
    "                # print(\"emotion_pred_: \"+ str(emotion_pred_))\n",
    "                valid_loss += loss.item()\n",
    "                emotion_correct += (emotion_pred_ == emotion_label).sum().item()\n",
    "                span_correct += (span_pred == span_label).sum().item()\n",
    "        \n",
    "        return valid_loss / len(self.valid_dataloader), emotion_correct / len(self.valid_dataloader) / self.batch_size, span_correct / len(self.valid_dataloader) / self.batch_size, emotion_label_list, emotion_pred_list\n",
    "        \n",
    "    def save_checkpoint(self, epoch, option):\n",
    "        checkpoint_path = os.path.join(self.save_checkpoint_dir, option + '/checkpoint_{}.pth'.format(epoch))\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(nn.Module):\n",
    "    def __init__(self, config_path):\n",
    "        super(Prediction, self).__init__()\n",
    "        self.build(config_path)\n",
    "    def build(self, config_path):\n",
    "        config = self.read_json(config_path)\n",
    "        self.id2label = config[\"id2label\"]\n",
    "        self.label2id = config[\"label2id\"]\n",
    "        self.submit_path = config[\"submit path\"]\n",
    "        self.device = config[\"device\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "    def predict(self, model, raw_dataset, dataset):\n",
    "        self.model = model.to(self.device)\n",
    "        self.model.eval()\n",
    "        pred_list = []\n",
    "        \n",
    "        self.test_dataloader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        logger_message = f'Predict '\n",
    "        progress_bar = tqdm(self.test_dataloader,\n",
    "                            desc=logger_message, initial=0, dynamic_ncols=True)\n",
    "        with torch.no_grad():\n",
    "            for _, data in enumerate(progress_bar):\n",
    "                conversation_id = data[\"conversation_ID\"]\n",
    "                paragraph = data[\"paragraph\"].to(self.device)\n",
    "                utter_id = data[\"utterance_ID\"]\n",
    "                token_text_pool = data[\"token_text_pool\"].to(self.device)\n",
    "                token_speaker_pool = data[\"token_speaker_pool\"].to(self.device)\n",
    "                emotion_pred, span_pred = self.model(paragraph, token_text_pool, token_speaker_pool)\n",
    "                \n",
    "                pred = self.convertpred2list(conversation_id, utter_id, emotion_pred, span_pred, casual_span_pool)\n",
    "                pred_list.extend(pred)\n",
    "        submit = self.convertdict2submit(self.convertpred2dict(raw_dataset, pred_list))\n",
    "        self.save_json(self.submit_path, submit)\n",
    "    def convertpred2list(self, conversation_id, utter_id, emotion_pred, span_pred, casual_span_pool):\n",
    "        pred_list = []\n",
    "        for i in range(len(emotion_pred)):\n",
    "            emotion = self.id2label[str(torch.argmax(emotion_pred[i]).item())]\n",
    "            emotion_string = str(utter_id[i].item()) + \"_\" + emotion\n",
    "            if emotion != \"neutral\":\n",
    "                # \n",
    "                span = torch.round(span_pred[i])\n",
    "                # print(\"span: \"+str(span))\n",
    "                # print(\"casual_span_pool: \"+str(casual_span_pool[i]))\n",
    "                for j in range(len(span)):\n",
    "                    if span[j] == 1:\n",
    "                        if casual_span_pool[i][j][0].item() == 0:\n",
    "                            break\n",
    "                        if casual_span_pool[i][j][1].item() == casual_span_pool[i][j][2].item():\n",
    "                            break\n",
    "                        span_string = str(int(casual_span_pool[i][j][0].item())) + \"_\" + str(int(casual_span_pool[i][j][1].item())) + \"_\" + str(int(casual_span_pool[i][j][2].item()))\n",
    "                        pred_dict = {}\n",
    "                        pred_dict[\"conversation_ID\"] = conversation_id[i].item()\n",
    "                        pred_dict[\"emotion-cause_pairs\"] = [emotion_string, span_string]\n",
    "                        # print(\"pred_dict: \"+str(pred_dict))\n",
    "                        pred_list.append(pred_dict)\n",
    "        return pred_list\n",
    "    def convertpred2dict(self, raw_dataset, pred_list):\n",
    "        dataset = self.convertlist2dict(raw_dataset)\n",
    "        # dict = \n",
    "        for i in range(len(pred_list)):\n",
    "            pred = pred_list[i]\n",
    "            conversation_id = pred[\"conversation_ID\"]\n",
    "            # print(\"conversation_id: \"+str(conversation_id))\n",
    "            emotion_cause_pairs = pred[\"emotion-cause_pairs\"]\n",
    "            # print(\"emotion_cause_pairs: \"+str(emotion_cause_pairs))\n",
    "            if \"emotion-cause_pairs\" in dataset[conversation_id]:\n",
    "                dataset[conversation_id][\"emotion-cause_pairs\"].append(emotion_cause_pairs)\n",
    "            else:\n",
    "                dataset[conversation_id][\"emotion-cause_pairs\"] = []\n",
    "        # print(dataset)\n",
    "        return dataset\n",
    "    def convertlist2dict(self, raw_dataset):\n",
    "        dataset = {}\n",
    "        for i in range(len(raw_dataset)):\n",
    "            conversation = raw_dataset[i]\n",
    "            conversation_ID = conversation[\"conversation_ID\"]\n",
    "            # if conversation_ID not in dataset.key\n",
    "            dataset[conversation_ID] = {\n",
    "                \"conversation_ID\": conversation_ID,\n",
    "                \"conversation\": conversation['conversation']\n",
    "            }\n",
    "        return dataset\n",
    "    def convertdict2submit(self, raw_dataset):\n",
    "        dataset = []\n",
    "        for key in raw_dataset.keys():\n",
    "            # print(\"key: \"+str(key))\n",
    "            sample = raw_dataset[key]\n",
    "            # print(\"sample: \"+str(sample))\n",
    "            dataset.append(sample)\n",
    "        return dataset\n",
    "    def read_json(self, file_path):\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data\n",
    "    def save_json(self, file_path, data):\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGG(nn.Module):\n",
    "    def __init__(self, config_path):\n",
    "        super(TGG, self).__init__()\n",
    "        self.build(config_path)\n",
    "        self.lstm = nn.LSTM(128, self.hidden_size, self.num_layers, batch_first=True, dropout=0.2, bidirectional=True)\n",
    "        self.lstma_projection = nn.Linear(2*self.num_layers*self.hidden_size, self.embedding_dim)\n",
    "        self.cat_layer = nn.Linear(2*self.embedding_dim, self.embedding_dim)\n",
    "        self.emotion_fc = nn.Linear(self.embedding_dim, self.label_num)\n",
    "        self.casual_feedforward = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    def build(self, config_path):\n",
    "        config = self.read_json(config_path)\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.embedding_dim = config[\"embedding_dim\"]\n",
    "        self.encoder_name = config[\"encoder_name\"]\n",
    "        self.label2id = config[\"label2id\"]\n",
    "        self.label_num = len(self.label2id)\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.device = config[\"device\"]\n",
    "        \n",
    "        main_part = AutoModel.from_pretrained(self.encoder_name)\n",
    "        self.embeddings = main_part.embeddings\n",
    "        self.encoder = main_part.encoder\n",
    "        self.pooler = main_part.pooler\n",
    "        \n",
    "    def forward(self, paragraph, token_text_pool, token_speaker_pool):\n",
    "        batch_size = paragraph.size(0)\n",
    "        device = paragraph.get_device()\n",
    "\n",
    "        h0 = torch.randn((2 * self.num_layers, batch_size, self.hidden_size), device=device)\n",
    "        c0 = torch.randn((2 * self.num_layers, batch_size, self.hidden_size), device=device)\n",
    "        output, (hn, cn) = self.lstm(token_text_pool, (h0, c0))\n",
    "        hn = hn.permute(1,0,2)\n",
    "        hn = self.lstma_projection(hn.reshape(batch_size, -1))\n",
    "        # print(\"x: \"+str(x.shape))\n",
    "        \n",
    "        _paragraph = self.embeddings(paragraph)\n",
    "        _paragraph = self.encoder(_paragraph)['last_hidden_state']\n",
    "        _paragraph = self.pooler(_paragraph)\n",
    "        # print(\"hn : \"+ str(hn.shape))\n",
    "        # print(\"cn : \"+ str(cn.shape))\n",
    "        # print(\"output : \"+ str(output.shape))\n",
    "        # print(\"_paragraph : \"+ str(_paragraph.shape))\n",
    "\n",
    "        _x = self.cat_layer(torch.cat([hn, _paragraph], dim=-1))\n",
    "        _e_category = self.emotion_fc(_x)\n",
    "        # print(\"_e_category : \"+ str(_e_category.shape))\n",
    "\n",
    "        # _candidate = self.embeddings(candidate)\n",
    "        # _candidate = self.encoder(_candidate)['last_hidden_state']\n",
    "        # _candidate = self.pooler(_candidate)\n",
    "\n",
    "\n",
    "        # _candidate = self.casual_feedforward(_candidate)\n",
    "\n",
    "        # _similarity = _e_category @ _candidate\n",
    "        _similarity = torch.rand((batch_size, 9, 2), device=device)\n",
    "        # print(\"_similarity : \"+ str(_similarity.shape))\n",
    "        return self.softmax(_e_category), _similarity\n",
    "    def read_json(self, file_path):\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"config.json\"\n",
    "dataset = read_json(\"../data/ECF 2.0/train/train.json\")\n",
    "trial_data = read_json(\"../data/ECF 2.0/trial/trial.json\")\n",
    "raw_trial_data = read_json(\"../data/ECF 2.0/trial/Subtask_1_trial.json\")\n",
    "\n",
    "n_train = int(0.8 * len(dataset))\n",
    "train_data, valid_data = dataset[:n_train], dataset[n_train:]\n",
    "train_dataset = ConversationDataset(config_path, train_data)\n",
    "valid_dataset = ConversationDataset(config_path, valid_data)\n",
    "model = TGG(config_path)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(\"\\\"\" + name + \"\\\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config_path)\n",
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_lstm\", batch_size=512)\n",
    "trial_dataset = ConversationDataset(config_path, trial_data, option=\"trial\")\n",
    "predict = Prediction(config_path)\n",
    "predict.predict(model, raw_trial_data, trial_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config_path)\n",
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_encoder\", batch_size=32)\n",
    "trial_dataset = ConversationDataset(config_path, trial_data, option=\"trial\")\n",
    "trainer = Trainer(config_path)\n",
    "trainer.train(model, optimizer, train_dataset=train_dataset, valid_dataset=valid_dataset, epochs=100, option=\"emotion_encoder_lstm\", batch_size=32)\n",
    "trial_dataset = ConversationDataset(config_path, trial_data, option=\"trial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
