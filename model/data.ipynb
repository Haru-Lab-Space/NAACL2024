{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_padding = 6\n",
    "right_padding = 2\n",
    "\n",
    "punctuation_error = [\n",
    "        \"%\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "def write_json(path, data):\n",
    "    with open(path, 'w') as file:\n",
    "        # Write the Python data structure as JSON to the file\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Create a string of all punctuation characters\n",
    "    punctuation_chars = string.punctuation\n",
    "\n",
    "    # Remove punctuation at the beginning and end of the string\n",
    "    cleaned_text = text.strip(punctuation_chars).strip().strip(punctuation_chars).strip().strip(punctuation_chars).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "def span(text, sub_text, s_ind=0):\n",
    "    sub_text = remove_punctuation(sub_text)\n",
    "    new_text = text.split()\n",
    "    if text == sub_text:\n",
    "        ss = s_ind\n",
    "        se = s_ind+len(new_text)\n",
    "        return ss, se, text\n",
    "    new_sub_text = sub_text\n",
    "    new_sub_text = new_sub_text.split()\n",
    "    check = True\n",
    "    for i in range(len(new_text)):\n",
    "        temp = i\n",
    "        for j in range(len(new_sub_text)):\n",
    "            if new_sub_text[j] != new_text[i + j]:\n",
    "                if j == len(new_sub_text)-1:\n",
    "                    for punctuation in punctuation_error:\n",
    "\n",
    "                        if new_sub_text[j]+punctuation == new_text[i + j]:\n",
    "                            # print(new_sub_text)\n",
    "                            new_sub_text[j] = new_sub_text[j]+punctuation \n",
    "                            ss = i\n",
    "                            se = i+j\n",
    "                            print(new_sub_text)\n",
    "                            return s_ind+ss, s_ind+se+1, ' '.join(new_sub_text)\n",
    "                check = False\n",
    "                break\n",
    "            else:\n",
    "                temp = i + j\n",
    "                check = True\n",
    "        if check == True:\n",
    "            ss = i\n",
    "            se = temp\n",
    "            return s_ind+ss, s_ind+se+1, sub_text\n",
    "\n",
    "def convertraw_to_train(data):\n",
    "    new_data = []\n",
    "    max_len = 0\n",
    "    for i in range(len(data)):\n",
    "        conversation_ID = data[i]['conversation_ID']\n",
    "        conversation = data[i]['conversation']\n",
    "\n",
    "        utterance_ID_pool = []\n",
    "        text_pool = []\n",
    "        speaker_pool = []\n",
    "        emotion_pool = {}\n",
    "        for j in range(len(conversation)):\n",
    "            utterance_ID_pool.append(conversation[j]['utterance_ID'])\n",
    "            text_pool.append(conversation[j]['text'])\n",
    "            if max_len < len(conversation[j]['text'].split()):\n",
    "                max_len = len(conversation[j]['text'].split())\n",
    "            speaker_pool.append(conversation[j]['speaker'])\n",
    "            emotion_pool[j+1] = {}\n",
    "            emotion_pool[j+1][\"property\"] = {}\n",
    "            emotion_pool[j+1][\"casual\"] = {}\n",
    "            if \"emotion\" in conversation[j].keys():\n",
    "                emotion_pool[j+1][\"property\"] = conversation[j]['emotion']\n",
    "\n",
    "        \n",
    "        if \"emotion-cause_pairs\" in data[i].keys():\n",
    "            cause_pairs_pool = []\n",
    "            cause_pairs = data[i]['emotion-cause_pairs']\n",
    "            for j in range(len(cause_pairs)):\n",
    "                emotion_utter = cause_pairs[j][0]\n",
    "                casual_utter = cause_pairs[j][1]\n",
    "                utter, emotion = emotion_utter.split(\"_\")\n",
    "                casual_utter, casual_text = casual_utter.split(\"_\")\n",
    "                if conversation_ID == 1049:\n",
    "                    print(\"cause_pairs[j][0]:\" +str(cause_pairs[j][0]))\n",
    "                    print(\"cause_pairs[j][1]:\" +str(cause_pairs[j][1]))\n",
    "                    print(\"utter:\" +str(utter))\n",
    "                    print(\"casual_utter:\" +str(casual_utter))\n",
    "                    print(\"int(utter) - left_padding :\" +str(int(utter) - left_padding))\n",
    "                    print(\"int(utter) + right_padding :\" +str(int(utter) + right_padding))\n",
    "                if int(utter) - left_padding > int(casual_utter):\n",
    "                    continue\n",
    "                if int(utter) + right_padding < int(casual_utter):\n",
    "                    continue\n",
    "                start, end, _ = span(text_pool[int(casual_utter)-1], casual_text)\n",
    "                emotion_pool[int(utter)][\"casual\"][int(casual_utter)] = {\n",
    "                    \"casual_text\": casual_text,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end\n",
    "                }\n",
    "\n",
    "\n",
    "        for j in range(len(conversation)):\n",
    "            start_ids = max(1, j-left_padding+1)\n",
    "            end_ids = min(j+right_padding+2, len(conversation)+1)\n",
    "            for k in range(start_ids, end_ids):\n",
    "                if k not in emotion_pool[j+1][\"casual\"].keys():\n",
    "                    emotion_pool[j+1][\"casual\"][k] = {\n",
    "                        \"casual_text\": \"\",\n",
    "                        \"start\": 0,\n",
    "                        \"end\": 0\n",
    "                    }\n",
    "\n",
    "            emotion_pool[j+1][\"casual\"] = dict(sorted(emotion_pool[j+1][\"casual\"].items()))\n",
    "            start_ids = max(0, j-left_padding)\n",
    "            end_ids = min(j+right_padding+1, len(conversation))\n",
    "            paragraph = \" \".join(text_pool[start_ids: end_ids])\n",
    "            \n",
    "            new_data.append({\n",
    "                \"conversation_ID\" : conversation_ID,\n",
    "                \"utterance_ID\" : utterance_ID_pool[j],\n",
    "                \"paragraph\": paragraph,\n",
    "                \"emotion\": emotion_pool[j+1],\n",
    "                \"text_pool\": text_pool[start_ids: end_ids],\n",
    "                \"speaker_pool\": speaker_pool[start_ids: end_ids],\n",
    "            })\n",
    "    print(max_len)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cause_pairs[j][0]:1_anger\n",
      "cause_pairs[j][1]:3_I had plans with Joey tonight and he left me this note .\n",
      "utter:1\n",
      "casual_utter:3\n",
      "int(utter) - left_padding :-5\n",
      "int(utter) + right_padding :3\n",
      "cause_pairs[j][0]:1_anger\n",
      "cause_pairs[j][1]:4_\" Pheebs , can not make it , got a date . Talk to you later . Big Daddy . \"\n",
      "utter:1\n",
      "casual_utter:4\n",
      "int(utter) - left_padding :-5\n",
      "int(utter) + right_padding :3\n",
      "cause_pairs[j][0]:2_surprise\n",
      "cause_pairs[j][1]:1_Joseph Francis Tribbiani are you home yet ? ! !\n",
      "utter:2\n",
      "casual_utter:1\n",
      "int(utter) - left_padding :-4\n",
      "int(utter) + right_padding :4\n",
      "cause_pairs[j][0]:3_anger\n",
      "cause_pairs[j][1]:3_I had plans with Joey tonight and he left me this note .\n",
      "utter:3\n",
      "casual_utter:3\n",
      "int(utter) - left_padding :-3\n",
      "int(utter) + right_padding :5\n",
      "cause_pairs[j][0]:3_anger\n",
      "cause_pairs[j][1]:4_\" Pheebs , can not make it , got a date . Talk to you later . Big Daddy . \"\n",
      "utter:3\n",
      "casual_utter:4\n",
      "int(utter) - left_padding :-3\n",
      "int(utter) + right_padding :5\n",
      "cause_pairs[j][0]:6_joy\n",
      "cause_pairs[j][1]:6_you know what nickname never caught on ? The Ross ... A ... Tron !\n",
      "utter:6\n",
      "casual_utter:6\n",
      "int(utter) - left_padding :0\n",
      "int(utter) + right_padding :8\n",
      "cause_pairs[j][0]:7_joy\n",
      "cause_pairs[j][1]:7_Hey !\n",
      "utter:7\n",
      "casual_utter:7\n",
      "int(utter) - left_padding :1\n",
      "int(utter) + right_padding :9\n",
      "cause_pairs[j][0]:8_anger\n",
      "cause_pairs[j][1]:3_I had plans with Joey tonight and he left me this note .\n",
      "utter:8\n",
      "casual_utter:3\n",
      "int(utter) - left_padding :2\n",
      "int(utter) + right_padding :10\n",
      "cause_pairs[j][0]:8_anger\n",
      "cause_pairs[j][1]:4_\" Pheebs , can not make it , got a date . Talk to you later . Big Daddy . \"\n",
      "utter:8\n",
      "casual_utter:4\n",
      "int(utter) - left_padding :2\n",
      "int(utter) + right_padding :10\n",
      "cause_pairs[j][0]:9_surprise\n",
      "cause_pairs[j][1]:8_Here is Joseph Francis !\n",
      "utter:9\n",
      "casual_utter:8\n",
      "int(utter) - left_padding :3\n",
      "int(utter) + right_padding :11\n",
      "cause_pairs[j][0]:9_surprise\n",
      "cause_pairs[j][1]:9_What are you middle naming me for ? !\n",
      "utter:9\n",
      "casual_utter:9\n",
      "int(utter) - left_padding :3\n",
      "int(utter) + right_padding :11\n",
      "cause_pairs[j][0]:10_anger\n",
      "cause_pairs[j][1]:3_I had plans with Joey tonight and he left me this note .\n",
      "utter:10\n",
      "casual_utter:3\n",
      "int(utter) - left_padding :4\n",
      "int(utter) + right_padding :12\n",
      "cause_pairs[j][0]:10_anger\n",
      "cause_pairs[j][1]:10_That does not give you the right to ditch me !\n",
      "utter:10\n",
      "casual_utter:10\n",
      "int(utter) - left_padding :4\n",
      "int(utter) + right_padding :12\n",
      "cause_pairs[j][0]:11_anger\n",
      "cause_pairs[j][1]:10_That does not give you the right to ditch me !\n",
      "utter:11\n",
      "casual_utter:10\n",
      "int(utter) - left_padding :5\n",
      "int(utter) + right_padding :13\n",
      "cause_pairs[j][0]:13_anger\n",
      "cause_pairs[j][1]:12_he is right , that is the rule .\n",
      "utter:13\n",
      "casual_utter:12\n",
      "int(utter) - left_padding :7\n",
      "int(utter) + right_padding :15\n",
      "cause_pairs[j][0]:13_anger\n",
      "cause_pairs[j][1]:13_I do not accept this rule .\n",
      "utter:13\n",
      "casual_utter:13\n",
      "int(utter) - left_padding :7\n",
      "int(utter) + right_padding :15\n",
      "cause_pairs[j][0]:14_anger\n",
      "cause_pairs[j][1]:11_you can cancel plans with friends if there is the possibility for sex !\n",
      "utter:14\n",
      "casual_utter:11\n",
      "int(utter) - left_padding :8\n",
      "int(utter) + right_padding :16\n",
      "cause_pairs[j][0]:15_anger\n",
      "cause_pairs[j][1]:11_you can cancel plans with friends if there is the possibility for sex !\n",
      "utter:15\n",
      "casual_utter:11\n",
      "int(utter) - left_padding :9\n",
      "int(utter) + right_padding :17\n",
      "cause_pairs[j][0]:15_anger\n",
      "cause_pairs[j][1]:15_I can not just be a way to kill time til you meet someone better !\n",
      "utter:15\n",
      "casual_utter:15\n",
      "int(utter) - left_padding :9\n",
      "int(utter) + right_padding :17\n",
      "cause_pairs[j][0]:16_anger\n",
      "cause_pairs[j][1]:11_you can cancel plans with friends if there is the possibility for sex !\n",
      "utter:16\n",
      "casual_utter:11\n",
      "int(utter) - left_padding :10\n",
      "int(utter) + right_padding :18\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "data = read_json(\"../data/ECF 2.0/train/Subtask_1_train.json\")\n",
    "new_data= convertraw_to_train(data)\n",
    "write_json(\"../data/ECF 2.0/train/train.json\", new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "data = read_json(\"../data/ECF 2.0/trial/Subtask_1_trial.json\")\n",
    "new_data= convertraw_to_train(data)\n",
    "write_json(\"../data/ECF 2.0/trial/trial.json\", new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
